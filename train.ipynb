{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "# from surprise import Reader, Dataset, SVD, evaluate\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "import pickle\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "md = pd. read_csv('./dataset/movies_metadata.csv')\n",
    "md.head()\n",
    "\n",
    "md['genres'] = md['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "\n",
    "md['year'] = pd.to_datetime(md['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)\n",
    "\n",
    "links_small = pd.read_csv('./dataset/links_small.csv')\n",
    "links_small = links_small[links_small['tmdbId'].notnull()]['tmdbId'].astype('int')\n",
    "\n",
    "md = md.drop([19730, 29503, 35587])\n",
    "\n",
    "#Check EDA Notebook for how and why I got these indices.\n",
    "md['id'] = md['id'].astype('int')\n",
    "\n",
    "smd = md[md['id'].isin(links_small)]\n",
    "\n",
    "'''\n",
    "# Movie Description Based\n",
    "\n",
    "smd['tagline'] = smd['tagline'].fillna('')\n",
    "smd['description'] = smd['overview'] + smd['tagline']\n",
    "smd['description'] = smd['description'].fillna('')\n",
    "\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(smd['description'])\n",
    "\n",
    "pickle.dump(tfidf_matrix, open(\"./model/tfidf1.pkl\", \"wb\"))\n",
    "\n",
    "# prediction \n",
    "# cosie similarity\n",
    "tf1 = pickle.load(open(\"./model/tfidf1.pkl\", 'rb'))\n",
    "\n",
    "cosine_sim = linear_kernel(tf1, tf1)\n",
    "\n",
    "smd = smd.reset_index()\n",
    "titles = smd['title']\n",
    "indices = pd.Series(smd.index, index=smd['title'])\n",
    "\n",
    "smd.to_csv('./dataset/tfid_smd.csv')\n",
    "\n",
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:31]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return titles.iloc[movie_indices]\n",
    "\n",
    "prediction = get_recommendations('The Godfather').head(10)\n",
    "print(prediction)\n",
    "'''\n",
    "'''\n",
    "get_recommendations('The Godfather').head(10)\n",
    "\n",
    "973      The Godfather: Part II\n",
    "8387                 The Family\n",
    "3509                       Made\n",
    "4196         Johnny Dangerously\n",
    "29               Shanghai Triad\n",
    "5667                       Fury\n",
    "2412             American Movie\n",
    "1582    The Godfather: Part III\n",
    "4221                    8 Women\n",
    "2159              Summer of Sam\n",
    "Name: title, dtype: object\n",
    "'''\n",
    "\n",
    "credits = pd.read_csv('./dataset/credits.csv')\n",
    "keywords = pd.read_csv('./dataset/keywords.csv')\n",
    "\n",
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "md['id'] = md['id'].astype('int')\n",
    "\n",
    "md = md.merge(credits, on='id')\n",
    "md = md.merge(keywords, on='id')\n",
    "\n",
    "smd = md[md['id'].isin(links_small)]\n",
    "\n",
    "\n",
    "smd['cast'] = smd['cast'].apply(literal_eval)\n",
    "smd['crew'] = smd['crew'].apply(literal_eval)\n",
    "smd['keywords'] = smd['keywords'].apply(literal_eval)\n",
    "smd['cast_size'] = smd['cast'].apply(lambda x: len(x))\n",
    "smd['crew_size'] = smd['crew'].apply(lambda x: len(x))\n",
    "\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "\n",
    "smd['director'] = smd['crew'].apply(get_director)\n",
    "smd['cast'] = smd['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "smd['cast'] = smd['cast'].apply(lambda x: x[:3] if len(x) >=3 else x)\n",
    "\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "\n",
    "smd['cast'] = smd['cast'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "\n",
    "smd['director'] = smd['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "smd['director'] = smd['director'].apply(lambda x: [x,x, x])\n",
    "\n",
    "s = smd.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'keyword'\n",
    "\n",
    "s = s.value_counts()\n",
    "s[:5]\n",
    "s = s[s > 1]\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "stemmer.stem('dogs')\n",
    "\n",
    "def filter_keywords(x):\n",
    "    words = []\n",
    "    for i in x:\n",
    "        if i in s:\n",
    "            words.append(i)\n",
    "    return words\n",
    "\n",
    "smd['keywords'] = smd['keywords'].apply(filter_keywords)\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "\n",
    "\n",
    "smd['soup'] = smd['keywords'] + smd['cast'] + smd['director'] + smd['genres']\n",
    "smd['soup'] = smd['soup'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "smd.to_csv('./dataset/count_smd.csv')\n",
    "\n",
    "count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "count_matrix = count.fit_transform(smd['soup'])\n",
    "\n",
    "# Dump the file\n",
    "pickle.dump(count_matrix, open(\"./model/count1.pkl\", \"wb\"))\n",
    "\n",
    "# Testing phase\n",
    "count1 = pickle.load(open(\"./model/count1.pkl\", 'rb'))\n",
    "\n",
    "cosine_sim = cosine_similarity(count1, count1)\n",
    "\n",
    "smd = smd.reset_index()\n",
    "titles = smd['title']\n",
    "indices = pd.Series(smd.index, index=smd['title'])\n",
    "\n",
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:31]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return titles.iloc[movie_indices]\n",
    "\n",
    "Metadata_prediction = get_recommendations('The Dark Knight').head(10)\n",
    "\n",
    "print(Metadata_prediction)\n",
    "\n",
    "'''\n",
    "8031         The Dark Knight Rises\n",
    "6218                 Batman Begins\n",
    "6623                  The Prestige\n",
    "2085                     Following\n",
    "7648                     Inception\n",
    "4145                      Insomnia\n",
    "3381                       Memento\n",
    "8613                  Interstellar\n",
    "7659    Batman: Under the Red Hood\n",
    "1134                Batman Returns\n",
    "Name: title, dtype: object\n",
    "'''\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8031         The Dark Knight Rises\n",
      "6218                 Batman Begins\n",
      "6623                  The Prestige\n",
      "2085                     Following\n",
      "7648                     Inception\n",
      "4145                      Insomnia\n",
      "3381                       Memento\n",
      "8613                  Interstellar\n",
      "7659    Batman: Under the Red Hood\n",
      "1134                Batman Returns\n",
      "Name: title, dtype: object\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n8031         The Dark Knight Rises\\n6218                 Batman Begins\\n6623                  The Prestige\\n2085                     Following\\n7648                     Inception\\n4145                      Insomnia\\n3381                       Memento\\n8613                  Interstellar\\n7659    Batman: Under the Red Hood\\n1134                Batman Returns\\nName: title, dtype: object\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3810jvsc74a57bd0e06a044399fcee55785cbe37120d77954f1d49f7727169dd83dc6ef8e554e324",
   "display_name": "Python 3.8.10 64-bit ('movie.env': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}